# This source tails the logs that are created by the Docker json-file logging driver
<source>
  @type tail
  tag foo.docker.*
  path /var/lib/docker/containers/*/*-json.log
  pos_file /tmp/docker.pos
  format json
  refresh_interval 10s
  time_key time
  time_format %FT%T.%L
</source>

<match foo.docker.**>
  remove_tag_prefix foo
  type detect_exceptions
  message log
  languages java, python
  multiline_flush_interval 0.1
</match>

#This uses the Docker metadata plugin to enrich data
<filter docker.var.lib.docker.containers.*.*.log>
  type docker_metadata
</filter>

#This makes use of the ECS Metadata plugin to enrich records with ECS metadata
<filter **>
  type ecs_metadata
</filter>

#This copies the FluentD field log over to message for increased usability within the Kibana Discover page
<match docker.**>
  @type record_reformer
  renew_record false
  enable_ruby false
  tag logcopy
  <record>
    message ${log}
  </record>
</match>

#This drops unnecessary keys (just log in this example, but could be extended to others)
<match logcopy>
  @type record_reformer
  remove_keys log
  renew_record false
  enable_ruby false
  tag final
</match>

<match fluent.**>
   @type null
</match>

#This is for sending to a file for testing prior to sending to Logz.io
#<match **>
#      type logzio_buffered
#      endpoint_url "#{ENV['LOGZ_IO_URL_1']}"
#      output_include_time true
#      output_include_tags true
#      buffer_type    file
#      buffer_path    /tmp/logsz_buffer
#      flush_interval 1s
#      buffer_chunk_limit 1m   # Logz.io has bulk limit of 10M. We recommend set this to 1M, to avoid oversized bulks
#</match>

#This is for sending to a file for testing prior to sending to Logz.io
<match **>
  @type file
  path /tmp/test0
  time_slice_format %Y%m%d
  time_slice_wait 10m
  time_format %Y%m%dT%H%M%S%z
  utc
</match>
